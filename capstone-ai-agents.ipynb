{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==========================================\n# MEDI-SIMPLIFIER: CAPSTONE PROJECT\n# Track: Agents for Good (Healthcare)\n# ==========================================\n\n# --- 1. INSTALLATION & SETUP ---\n# Uncomment the lines below if running in a new environment\n# !pip install -q langchain langchain-openai google-search-results\n\nimport os\nimport sys\nfrom typing import List\n\n# LangChain Imports\nfrom langchain.agents import Tool, initialize_agent, AgentType\nfrom langchain.memory import ConversationBufferWindowMemory\nfrom langchain_openai import ChatOpenAI\nfrom langchain_community.utilities import SerpAPIWrapper\nfrom langchain.prompts import SystemMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n\n# --- 2. CONFIGURATION (API KEYS) ---\n# ‚ö†Ô∏è REPLACE THESE WITH YOUR ACTUAL KEYS BEFORE RUNNING\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY_HERE\"\nos.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_KEY_HERE\"\n\nclass MedicalInsightEngine:\n    \"\"\"\n    A robust agentic system designed to interpret complex medical text.\n    Architecture:\n    - Logic Engine: GPT-4 (Orchestrator)\n    - Tools: Real-time Web Search (Verification)\n    - Memory: Rolling Window Buffer (Context Retention)\n    \"\"\"\n\n    def __init__(self):\n        self._validate_keys()\n        self.llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4\")\n        self.memory = self._initialize_memory()\n        self.tools = self._initialize_tools()\n        self.agent = self._build_agent()\n        \n    def _validate_keys(self):\n        \"\"\"Ensures API keys are present to prevent runtime crashes.\"\"\"\n        if \"YOUR_\" in os.environ.get(\"OPENAI_API_KEY\", \"\"):\n            print(\"‚ùå ERROR: Please update your API Keys in the Configuration section.\")\n            sys.exit(1)\n\n    def _initialize_memory(self):\n        \"\"\"\n        Creates a 'Short-term Memory' buffer.\n        We use k=5 to keep the last 5 exchanges in context, simulating\n        a doctor remembering the immediate conversation history.\n        \"\"\"\n        return ConversationBufferWindowMemory(\n            memory_key=\"chat_history\",\n            k=5,\n            return_messages=True\n        )\n\n    def _initialize_tools(self) -> List[Tool]:\n        \"\"\"\n        Defines the external tools the agent can use.\n        Using Google Search to verify latest medical guidelines.\n        \"\"\"\n        search = SerpAPIWrapper()\n        return [\n            Tool(\n                name=\"Clinical Verification Search\",\n                func=search.run,\n                description=(\n                    \"CRITICAL: Use this tool to define medical terms, \"\n                    \"check standard reference ranges (e.g., blood pressure), \"\n                    \"or verify side effects. Do not guess.\"\n                )\n            )\n        ]\n\n    def _build_agent(self):\n        \"\"\"\n        Constructs the ReAct (Reason + Act) Agent.\n        \"\"\"\n        return initialize_agent(\n            tools=self.tools,\n            llm=self.llm,\n            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n            verbose=True, # Prints the \"thought process\" to the console\n            memory=self.memory,\n            handle_parsing_errors=True\n        )\n\n    def run_session(self, user_input: str):\n        \"\"\"\n        The main entry point for processing a user query.\n        \"\"\"\n        print(f\"\\nüîç PROCESSING: '{user_input}'...\")\n        try:\n            # We wrap the user input in a specific instruction to force formatting\n            enhanced_prompt = (\n                f\"User Query: {user_input}\\n\\n\"\n                \"INSTRUCTIONS:\\n\"\n                \"1. If this is medical text, search for the terms to verify them.\\n\"\n                \"2. Translate it into simple, 5th-grade English.\\n\"\n                \"3. Provide a 'Doctor Q&A Checklist' at the end.\\n\"\n                \"4. Be empathetic but factual.\"\n            )\n            \n            response = self.agent.run(enhanced_prompt)\n            return response\n        except Exception as e:\n            return f\"System Error: {str(e)}\"\n\n# --- 3. EXECUTION SCENARIO ---\n\ndef run_demonstration():\n    print(\"üè• BOOTING MEDI-SIMPLIFIER AGENT...\\n\")\n    \n    # Instantiate the Engine\n    engine = MedicalInsightEngine()\n    \n    # --- INTERACTION 1: ONBOARDING (Setting Context) ---\n    print(\"--- [Step 1] Patient Onboarding ---\")\n    patient_profile = \"I am a 65-year-old male with Type 2 Diabetes. I live alone.\"\n    print(f\"User: {patient_profile}\")\n    \n    response_1 = engine.run_session(patient_profile)\n    print(f\"\\nü§ñ AGENT:\\n{response_1}\\n\")\n    print(\"=\"*60)\n\n    # --- INTERACTION 2: COMPLEX INPUT (The Core Problem) ---\n    print(\"\\n--- [Step 2] Processing Medical Report ---\")\n    complex_report = (\n        \"I received my lab results. It says: \"\n        \"'HbA1c is 8.5%, indicative of poor glycemic control. \"\n        \"Microalbuminuria present. Initiate ACE inhibitor therapy.'\"\n    )\n    print(f\"User: {complex_report}\")\n    \n    response_2 = engine.run_session(complex_report)\n    \n    print(f\"\\nü§ñ AGENT RESPONSE:\\n{response_2}\")\n    print(\"\\n\" + \"=\"*60)\n    \n    # --- INTERACTION 3: MEDICATION INQUIRY (Follow up) ---\n    print(\"\\n--- [Step 3] Medication Safety Check ---\")\n    med_question = \"My doctor mentioned 'Lisinopril'. Is that safe for my kidneys?\"\n    print(f\"User: {med_question}\")\n    \n    response_3 = engine.run_session(med_question)\n    print(f\"\\nü§ñ AGENT RESPONSE:\\n{response_3}\")\n\nif __name__ == \"__main__\":\n    run_demonstration()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}