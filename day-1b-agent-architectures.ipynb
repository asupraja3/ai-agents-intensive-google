{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T22:56:30.897324Z","iopub.execute_input":"2025-11-11T22:56:30.897613Z","iopub.status.idle":"2025-11-11T22:56:30.902543Z","shell.execute_reply.started":"2025-11-11T22:56:30.897556Z","shell.execute_reply":"2025-11-11T22:56:30.901705Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T22:56:44.248094Z","iopub.execute_input":"2025-11-11T22:56:44.248527Z","iopub.status.idle":"2025-11-11T22:56:44.439866Z","shell.execute_reply.started":"2025-11-11T22:56:44.248497Z","shell.execute_reply":"2025-11-11T22:56:44.439086Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T22:56:47.594432Z","iopub.execute_input":"2025-11-11T22:56:47.595120Z","iopub.status.idle":"2025-11-11T22:57:30.165135Z","shell.execute_reply.started":"2025-11-11T22:56:47.595095Z","shell.execute_reply":"2025-11-11T22:57:30.164369Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T22:57:33.655216Z","iopub.execute_input":"2025-11-11T22:57:33.655600Z","iopub.status.idle":"2025-11-11T22:57:33.660219Z","shell.execute_reply.started":"2025-11-11T22:57:33.655575Z","shell.execute_reply":"2025-11-11T22:57:33.659258Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:00:41.815265Z","iopub.execute_input":"2025-11-11T23:00:41.816272Z","iopub.status.idle":"2025-11-11T23:00:41.822952Z","shell.execute_reply.started":"2025-11-11T23:00:41.816240Z","shell.execute_reply":"2025-11-11T23:00:41.821924Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:03:46.302790Z","iopub.execute_input":"2025-11-11T23:03:46.303545Z","iopub.status.idle":"2025-11-11T23:03:46.309175Z","shell.execute_reply.started":"2025-11-11T23:03:46.303491Z","shell.execute_reply":"2025-11-11T23:03:46.308261Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:08:25.915493Z","iopub.execute_input":"2025-11-11T23:08:25.916605Z","iopub.status.idle":"2025-11-11T23:08:25.924260Z","shell.execute_reply.started":"2025-11-11T23:08:25.916572Z","shell.execute_reply":"2025-11-11T23:08:25.923421Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:09:12.516910Z","iopub.execute_input":"2025-11-11T23:09:12.517243Z","iopub.status.idle":"2025-11-11T23:09:19.480242Z","shell.execute_reply.started":"2025-11-11T23:09:12.517220Z","shell.execute_reply":"2025-11-11T23:09:19.479491Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > Quantum computing advancements are set to significantly transform AI by enabling faster model training, improving performance, and allowing AI to tackle currently intractable problems in fields like drug discovery and materials science. Quantum AI also promises more efficient data processing and natural language understanding, as well as better optimization for AI models and real-world systems, potentially leading to more sustainable AI solutions.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:17:25.848555Z","iopub.execute_input":"2025-11-11T23:17:25.848961Z","iopub.status.idle":"2025-11-11T23:17:25.854709Z","shell.execute_reply.started":"2025-11-11T23:17:25.848935Z","shell.execute_reply":"2025-11-11T23:17:25.853745Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:28:38.920178Z","iopub.execute_input":"2025-11-11T23:28:38.920989Z","iopub.status.idle":"2025-11-11T23:28:38.926105Z","shell.execute_reply.started":"2025-11-11T23:28:38.920962Z","shell.execute_reply":"2025-11-11T23:28:38.925096Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:28:44.608580Z","iopub.execute_input":"2025-11-11T23:28:44.608924Z","iopub.status.idle":"2025-11-11T23:28:44.614615Z","shell.execute_reply.started":"2025-11-11T23:28:44.608899Z","shell.execute_reply":"2025-11-11T23:28:44.613679Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:20:31.214793Z","iopub.execute_input":"2025-11-11T23:20:31.215514Z","iopub.status.idle":"2025-11-11T23:20:31.220458Z","shell.execute_reply.started":"2025-11-11T23:20:31.215482Z","shell.execute_reply":"2025-11-11T23:20:31.219438Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:20:45.098482Z","iopub.execute_input":"2025-11-11T23:20:45.098793Z","iopub.status.idle":"2025-11-11T23:20:51.885588Z","shell.execute_reply.started":"2025-11-11T23:20:45.098772Z","shell.execute_reply":"2025-11-11T23:20:51.884554Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > ## Blog Outline:\n\n**Headline:** Unleash the Power of Collaboration: How Multi-Agent Systems Can Revolutionize Your Development Workflow\n\n**Introduction Hook:** Are you tired of monolithic codebases and complex, single-threaded development processes? Imagine a world where your software can break down tasks, delegate intelligently, and even learn from its own actions. Welcome to the exciting realm of Multi-Agent Systems (MAS), a paradigm shift that's empowering developers to build more robust, adaptable, and intelligent applications than ever before.\n\n---\n\n**Main Section 1: Enhanced Modularity and Specialization**\n\n*   **Breaking Down Complexity:** MAS allows you to decompose large, intricate problems into smaller, manageable sub-problems, each handled by a dedicated agent. This leads to cleaner code and easier debugging.\n*   **Expert Agents for Specific Tasks:** Develop specialized agents that excel at particular functions (e.g., data processing, UI rendering, network communication). This promotes code reuse and allows teams to focus on core competencies.\n*   **Decentralized Control and Resilience:** If one agent fails, the system doesn't necessarily collapse. Other agents can often compensate or adapt, leading to more resilient applications.\n\n**Main Section 2: Improved Adaptability and Learning Capabilities**\n\n*   **Dynamic Problem Solving:** Agents can react to changing environments and unexpected events in real-time, making your software more agile and responsive.\n*   **Emergent Behavior and Collective Intelligence:** Complex behaviors can emerge from the interactions of simple agents, leading to innovative solutions that might not have been explicitly programmed.\n*   **Machine Learning Integration:** MAS provides a natural framework for integrating machine learning models, allowing agents to learn from data and improve their performance over time.\n\n**Main Section 3: Streamlined Collaboration and Resource Management**\n\n*   **Intelligent Task Allocation:** Agents can negotiate and coordinate to efficiently distribute workload, ensuring optimal resource utilization and faster completion times.\n*   **Parallel Processing on Steroids:** MAS inherently supports parallel execution, allowing different agents to work on tasks simultaneously, significantly boosting performance.\n*   **Simulation and Testing Environments:** MAS can be used to create sophisticated simulation environments, allowing developers to test and validate complex systems before deployment.\n\n**Main Section 4: Future-Proofing Your Software**\n\n*   **Scalability by Design:** As your application grows, you can simply add more agents or enhance existing ones, making scalability a more organic process.\n*   **Agile Development Practices:** The modular nature of MAS aligns perfectly with agile methodologies, allowing for iterative development and rapid prototyping.\n*   **Opening Doors to New Possibilities:** From AI-powered assistants to autonomous systems, MAS is the foundation for the next generation of intelligent software.\n\n---\n\n**Concluding Thought:** Embracing Multi-Agent Systems isn't just about adopting a new technology; it's about adopting a new way of thinking about software development. By fostering collaboration, promoting adaptability, and unlocking emergent intelligence, MAS empowers you to build software that is not only more powerful and efficient but also more resilient and future-ready. Are you ready to join the collaborative revolution?\nWriterAgent > ## Unleash the Power of Collaboration: How Multi-Agent Systems Can Revolutionize Your Development Workflow\n\nAre you tired of monolithic codebases and complex, single-threaded development processes? Imagine a world where your software can break down tasks, delegate intelligently, and even learn from its own actions. Welcome to the exciting realm of Multi-Agent Systems (MAS), a paradigm shift that's empowering developers to build more robust, adaptable, and intelligent applications than ever before.\n\nMAS fundamentally changes how we approach software by breaking down intricate problems into smaller, manageable sub-problems, each handled by a dedicated agent. This leads to enhanced modularity, cleaner code, and easier debugging. You can develop specialized agents for specific functions, promoting code reuse and allowing your teams to focus on core competencies. Crucially, this decentralized control offers greater resilience; if one agent falters, others can often compensate, preventing system collapse.\n\nBeyond structure, MAS brings unparalleled adaptability. Agents can react dynamically to changing environments and unexpected events in real-time, making your software more agile. Complex, emergent behaviors can arise from simple agent interactions, paving the way for innovative solutions. MAS also provides a natural framework for integrating machine learning, allowing your agents to learn and improve over time.\n\nFurthermore, MAS streamlines collaboration and resource management. Intelligent task allocation ensures efficient workload distribution and optimal resource utilization. The inherent support for parallel processing significantly boosts performance, as agents work concurrently.\n\nEmbracing Multi-Agent Systems isn't just adopting new tech; it's a new way of thinking. By fostering collaboration, promoting adaptability, and unlocking emergent intelligence, MAS empowers you to build software that's powerful, efficient, resilient, and future-ready. Are you ready to join the collaborative revolution?\nEditorAgent > ## Unleash the Power of Collaboration: How Multi-Agent Systems Can Revolutionize Your Development Workflow\n\nAre you tired of wrestling with monolithic codebases and navigating the complexities of single-threaded development? Imagine a software development process where tasks are intelligently broken down, delegated, and where your applications can even learn from their own actions. This is the exciting future offered by Multi-Agent Systems (MAS), a transformative paradigm that empowers developers to build more robust, adaptable, and intelligent applications than ever before.\n\nAt its core, MAS revolutionizes software development by decomposing intricate problems into smaller, more manageable sub-problems, each assigned to a dedicated agent. This approach fosters enhanced modularity, leading to cleaner codebases and significantly simplifying the debugging process. You can create specialized agents, each an expert in a specific function, which promotes code reuse and allows your development teams to concentrate on their core strengths. Critically, this decentralized control architecture offers a substantial increase in resilience; should one agent encounter an issue, others can often compensate or adapt, preventing a catastrophic system failure.\n\nBeyond structural improvements, MAS provides unparalleled adaptability. Agents are designed to react dynamically to changing environments and unforeseen events in real-time, making your software inherently more agile and responsive. Furthermore, complex, emergent behaviors can naturally arise from the interactions of simple agents, paving the way for truly innovative solutions. MAS also presents a natural and powerful framework for integrating machine learning, enabling your agents to learn from data and continuously improve their performance over time.\n\nMAS also fundamentally streamlines collaboration and resource management within your development projects. Intelligent task allocation ensures efficient workload distribution, leading to optimal resource utilization and faster project completion. The inherent support for parallel processing, where agents operate concurrently, significantly boosts overall performance.\n\nAdopting Multi-Agent Systems is more than just integrating new technology; it represents a fundamental shift in how we conceptualize software development. By fostering collaboration, promoting adaptability, and unlocking emergent intelligence, MAS equips you to build software that is powerful, efficient, resilient, and truly future-ready. Are you ready to join the collaborative revolution in software development?\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:27:24.887170Z","iopub.execute_input":"2025-11-11T23:27:24.887591Z","iopub.status.idle":"2025-11-11T23:27:24.893772Z","shell.execute_reply.started":"2025-11-11T23:27:24.887563Z","shell.execute_reply":"2025-11-11T23:27:24.892760Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:27:51.875158Z","iopub.execute_input":"2025-11-11T23:27:51.875807Z","iopub.status.idle":"2025-11-11T23:27:51.881098Z","shell.execute_reply.started":"2025-11-11T23:27:51.875781Z","shell.execute_reply":"2025-11-11T23:27:51.880247Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:29:01.321687Z","iopub.execute_input":"2025-11-11T23:29:01.322023Z","iopub.status.idle":"2025-11-11T23:29:01.327851Z","shell.execute_reply.started":"2025-11-11T23:29:01.322001Z","shell.execute_reply":"2025-11-11T23:29:01.326988Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:29:35.711229Z","iopub.execute_input":"2025-11-11T23:29:35.711850Z","iopub.status.idle":"2025-11-11T23:29:35.717767Z","shell.execute_reply.started":"2025-11-11T23:29:35.711803Z","shell.execute_reply":"2025-11-11T23:29:35.716744Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:30:01.222073Z","iopub.execute_input":"2025-11-11T23:30:01.222628Z","iopub.status.idle":"2025-11-11T23:30:01.228429Z","shell.execute_reply.started":"2025-11-11T23:30:01.222599Z","shell.execute_reply":"2025-11-11T23:30:01.227357Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:30:07.451772Z","iopub.execute_input":"2025-11-11T23:30:07.452476Z","iopub.status.idle":"2025-11-11T23:30:14.032013Z","shell.execute_reply.started":"2025-11-11T23:30:07.452450Z","shell.execute_reply":"2025-11-11T23:30:14.031256Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **Key AI/ML Trends for 2025**\n\nThree significant AI/ML trends shaping the technology landscape in 2025 are:\n\n1.  **Generative AI Expansion:** This trend focuses on AI models creating diverse content, including text, images, video, and music. Companies like Google (with models like Imagen and Muse) and OpenAI (GPT models) are at the forefront of this development. Its impact is revolutionizing content creation, enhancing artistic expression, and creating new practical applications across industries.\n\n2.  **Explainable AI (XAI):** As AI adoption grows, transparency in AI decision-making is becoming crucial. XAI aims to create understandable and trustworthy AI systems, especially vital in sensitive sectors like healthcare and finance. This trend helps foster trust and meet regulatory requirements.\n\n3.  **Agentic AI & Automation:** AI systems are increasingly capable of acting autonomously and making decisions. Companies like H2O.ai are developing \"Agentic AI.\" This trend is transforming industries such as logistics and transportation through autonomous systems and improving productivity by automating routine tasks across various sectors.\n\n**Main Companies Involved:** Major players in the AI/ML space include Google, Microsoft, Amazon, NVIDIA, IBM, and OpenAI.\n\n**Potential Impact:** These trends are driving significant advancements, leading to increased operational efficiency, enhanced customer experiences, and innovative solutions. However, challenges related to data privacy, ethical considerations, and workforce adaptation are also highlighted, requiring thoughtful management to harness AI's full potential.\nFinanceResearcher > ## Daily Executive Briefing: November 11, 2025\n\n**Technology:**\n\n*   **Agentic AI and Context Engineering:** AI is moving beyond simple chatbots to \"agentic AI\" that performs complex tasks autonomously. This requires sophisticated \"context engineering\" to feed models structured information for reliable performance. Market implication: Increased automation across industries, demanding new skillsets for AI management. Future outlook: Agentic AI will become more integrated, orchestrating multiple AI systems for complex decision-making.\n*   **AI Workload Infrastructure Demands:** Training and running AI models require massive GPU resources, pushing infrastructure orchestration to new scales. Cloud providers and enterprises are optimizing Kubernetes for efficient GPU utilization. Market implication: Significant investment in cloud infrastructure and specialized hardware. Future outlook: Continued innovation in hardware and orchestration strategies for AI workloads.\n*   **Cybersecurity Evolution:** The rise of AI-powered cyberattacks necessitates advanced AI-driven security solutions. Trust and regulation are becoming critical as AI plays a larger role in operational control. Market implication: Growing demand for robust cybersecurity measures and AI governance. Future outlook: An ongoing arms race between AI-enabled attacks and defenses, with a focus on AI trust and safety.\n\n**Health:**\n\n*   **AI in Medical Diagnosis and Drug Discovery:** AI is increasingly used for early disease detection (e.g., cancer, heart issues) and accelerating drug discovery and clinical trials. Market implication: Potential for improved patient outcomes and reduced healthcare costs. Future outlook: Wider adoption of AI-powered diagnostic tools and personalized medicine.\n*   **Virtual Hospitals and Remote Healthcare:** Telemedicine is evolving into \"virtual hospitals,\" offering comprehensive healthcare services remotely. Wearable technology enables more in-home patient treatment. Market implication: Increased accessibility to healthcare, particularly in underserved areas. Future outlook: A more decentralized healthcare system with greater patient empowerment.\n*   **Focus on Gut Health and Functional Foods:** Consumers are prioritizing digestive wellness and seeking foods with added benefits like probiotics and adaptogens. Market implication: Growth in the functional food and supplement market. Future outlook: Continued consumer demand for health-promoting food ingredients.\n\n**Finance:**\n\n*   **AI Integration in Financial Systems:** AI is being integrated into financial systems for data-backed decision-making, risk analysis, and fraud detection. Market implication: Increased efficiency and accuracy in financial operations. Future outlook: AI will be a dominant force in shaping financial strategies and operations.\n*   **Mega Mergers and Banking Consolidation:** Particularly in India, there's a trend towards mega mergers in the banking sector to create larger, more resilient institutions. Market implication: Shifting competitive landscape and potential for increased efficiency in financial services. Future outlook: Continued consolidation and structural changes in the financial industry.\n*   **Market Volatility and Cautious Economic Outlook:** Global equity markets are experiencing volatility, with a conservative outlook for the world economy. The Federal Reserve is navigating monetary policy cautiously amidst lingering inflation concerns. Market implication: Investors and businesses need to manage risks associated with market fluctuations and economic uncertainty. Future outlook: Continued vigilance regarding inflation, interest rates, and geopolitical risks.\nHealthResearcher > Here's a brief overview of recent breakthroughs in Tech, Health, and Finance:\n\n**Technology:**\n\n*   **AI and Machine Learning Advancements:** Sophisticated AI is now powering applications across industries, enhancing automation, image recognition, and natural language processing. Tools like ChatGPT exemplify this, with widespread adoption and rapid iteration expected in specialized fields.\n*   **5G Connectivity:** The rollout of 5G has brought significantly faster speeds and lower latency, enabling advancements in areas like autonomous vehicles and remote healthcare.\n*   **Extended Reality (XR - AR/VR):** These immersive technologies are rapidly growing, finding applications in gaming, education, training, and remote collaboration, blending physical and virtual environments.\n\n**Health:**\n\n*   **mRNA Vaccines:** The success of COVID-19 mRNA vaccines has opened new avenues for rapid vaccine development for other diseases, with trials underway for conditions like shingles.\n*   **CRISPR Gene Editing:** This technology allows for precise alteration of DNA to correct genetic defects, holding future potential to treat genetic diseases like sickle cell anemia and muscular dystrophy.\n*   **Advanced Medical Imaging and Implants:** Breakthroughs include AR/VR for surgical guidance and patient visualization, and brain implants enabling speech for individuals with paralysis.\n\n**Finance:**\n\n*   **AI-Powered Personalization:** AI is transforming FinTech by enhancing decision-making accuracy, improving operational efficiency, and personalizing customer experiences.\n*   **Embedded Finance:** Financial services are increasingly integrated into non-financial platforms, allowing for seamless transactions and offerings like instant merchant funding.\n*   **Digital Payments and Blockchain:** Digital payment adoption continues to surge, while blockchain technology enhances security and transparency in finance, paving the way for decentralized finance (DeFi) and tokenized assets.\n\n**Estimated Timelines:**\n\n*   **AI and Machine Learning:** Already in widespread use, with rapid advancements and deeper integration into specialized sectors expected within the next 1-3 years.\n*   **mRNA Vaccines:** Applications beyond infectious diseases are actively being developed and are likely to see broader implementation within 3-5 years.\n*   **CRISPR Gene Editing:** While practical applications are in their infancy, therapeutic uses for genetic diseases are anticipated within the next 5-10 years.\n*   **Embedded Finance & AI in Finance:** These trends are rapidly evolving, with significant expansion expected within the next 1-3 years.\n*   **Blockchain & DeFi:** Continued growth and adoption are anticipated, with more widespread use cases emerging in the next 3-5 years.\nAggregatorAgent > Here's an executive summary combining the provided research findings:\n\n**Executive Summary: Key Technology, Health, and Finance Innovations**\n\nThe landscape of innovation is rapidly advancing, driven significantly by AI and Machine Learning. Key trends for 2025 include the expansion of **Generative AI** for content creation and **Agentic AI**, enabling autonomous task execution and driving automation across industries. This surge in AI necessitates robust **infrastructure**, particularly GPU resources, and advanced, AI-driven **cybersecurity** solutions, emphasizing the growing importance of AI trust and governance.\n\nIn health, breakthroughs like **mRNA vaccines** are extending beyond infectious diseases, while **CRISPR gene editing** holds immense potential for treating genetic disorders. AI is revolutionizing medical diagnosis and drug discovery, complementing advancements in remote healthcare and virtual hospitals.\n\nFinancially, AI integration is enhancing decision-making, risk analysis, and customer personalization. The rise of **embedded finance** and continued growth in digital payments and blockchain are transforming financial services. Despite these innovations, a cautious economic outlook and market volatility require careful navigation. The interconnectedness of these trends underscores a future where AI and advanced technologies are foundational to progress across all sectors.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:44:18.883544Z","iopub.execute_input":"2025-11-11T23:44:18.884010Z","iopub.status.idle":"2025-11-11T23:44:18.890291Z","shell.execute_reply.started":"2025-11-11T23:44:18.883981Z","shell.execute_reply":"2025-11-11T23:44:18.889356Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:47:57.114272Z","iopub.execute_input":"2025-11-11T23:47:57.114687Z","iopub.status.idle":"2025-11-11T23:47:57.121050Z","shell.execute_reply.started":"2025-11-11T23:47:57.114662Z","shell.execute_reply":"2025-11-11T23:47:57.120078Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:00:55.705564Z","iopub.execute_input":"2025-11-12T00:00:55.705896Z","iopub.status.idle":"2025-11-12T00:00:55.711477Z","shell.execute_reply.started":"2025-11-12T00:00:55.705873Z","shell.execute_reply":"2025-11-12T00:00:55.710521Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:02:22.447980Z","iopub.execute_input":"2025-11-12T00:02:22.448403Z","iopub.status.idle":"2025-11-12T00:02:22.455384Z","shell.execute_reply.started":"2025-11-12T00:02:22.448375Z","shell.execute_reply":"2025-11-12T00:02:22.454213Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:03:17.561013Z","iopub.execute_input":"2025-11-12T00:03:17.561891Z","iopub.status.idle":"2025-11-12T00:03:17.567559Z","shell.execute_reply.started":"2025-11-12T00:03:17.561859Z","shell.execute_reply":"2025-11-12T00:03:17.566588Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:03:40.285725Z","iopub.execute_input":"2025-11-12T00:03:40.286013Z","iopub.status.idle":"2025-11-12T00:03:46.714083Z","shell.execute_reply.started":"2025-11-12T00:03:40.285993Z","shell.execute_reply":"2025-11-12T00:03:46.713419Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias, keeper of the Widow‚Äôs Wail, polished the great lens, its beam a familiar caress against the inky sea. Tonight, however, the salt spray tasted different, charged with an unknown energy. Descending to his small study, he found it‚Äîa rolled parchment, tucked beneath his worn logbook. It wasn‚Äôt paper, but something like dried kelp, and it pulsed with a soft, aquamarine light. Unfurling it, Elias gasped. A map, but not of any coast he knew. Islands like scattered jewels, marked with symbols that danced and shifted, glowed against the dark material. A single, larger island, shaped like a coiled serpent, shimmered brightest, a faint, melodic hum emanating from its luminous contours. The sea outside roared, but Elias, captivated, felt a new, uncharted tide pulling him.\nCriticAgent > Here's a review of your story:\n\nThe story sets up an intriguing premise with a good sense of atmosphere. The discovery of the glowing map is a strong hook.\n\nHere are a couple of suggestions for improvement:\n\n1.  **Show, Don't Just Tell Elias's Reaction:** While you mention Elias \"gasped\" and felt \"captivated,\" consider showing his physical reactions more. Does his hand tremble as he touches the map? Does his breath catch in his throat? Does he lean closer, his eyes wide with wonder and perhaps a touch of fear? More visceral reactions will draw the reader deeper into his experience.\n2.  **Elaborate on the \"Unknown Energy\":** You mention the salt spray tasted \"different, charged with an unknown energy.\" This is a great sensory detail, but it could be expanded. How did this energy manifest *before* the map was found? Was it just a feeling, or were there subtler signs Elias, as the lighthouse keeper, might have noticed (e.g., unusual currents, strange lights on the water, a peculiar silence)? This could foreshadow the map's arrival.\nRefinerAgent > Elias, keeper of the Widow‚Äôs Wail, polished the great lens, its beam a familiar caress against the inky sea. Tonight, however, the salt spray tasted different, charged with an unknown energy that made the fine hairs on his arms prickle. A strange, almost imperceptible hum vibrated through the stone tower, and the gulls, usually raucous, had fallen into an unnerving silence. Descending to his small study, the air thick with the scent of brine and something wild, he found it‚Äîa rolled parchment, tucked beneath his worn logbook. It wasn‚Äôt paper, but something like dried kelp, and it pulsed with a soft, aquamarine light.\n\nElias‚Äôs breath hitched. His hand, usually steady from years of maintaining the lamp, trembled as he reached for the object. It felt cool, almost alive, beneath his fingertips. Unfurling it, he gasped, his eyes widening. A map, but not of any coast he knew. Islands like scattered jewels, marked with symbols that danced and shifted, glowed against the dark material. A single, larger island, shaped like a coiled serpent, shimmered brightest, a faint, melodic hum emanating from its luminous contours. He leaned closer, his heart pounding a frantic rhythm against his ribs, a mix of wonder and a primal fear coiling in his gut. The sea outside roared, a familiar sound that now seemed distant, muted. Elias, utterly captivated, felt a new, uncharted tide pulling him, a siren song from the heart of the glowing sea.\nCriticAgent > Your revised story is excellent! It successfully incorporates the suggestions for improvement, creating a more immersive and atmospheric experience.\n\nHere's a breakdown of what works well:\n\n*   **Character:** Elias's internal experience and physical reactions are much more palpable. The detail about his \"usually steady\" hand trembling adds significant weight to his discovery.\n*   **Plot:** The pacing is strong. The build-up of the strange atmosphere and Elias's discovery of the map are well-balanced, leading to a compelling climax of wonder and fear.\n*   **Pacing:** The pacing is effective. The story starts with a subtle shift in atmosphere, building tension towards the reveal of the map. The final sentences effectively convey Elias's enthrallment and the promise of future adventure.\n\nThis version is well-written and complete.\n\nAPPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}